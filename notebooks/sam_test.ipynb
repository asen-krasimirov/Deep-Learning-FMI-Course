{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Kaggle Environment and Install Libraries\n",
    "\n",
    "!pip install -q ultralytics\n",
    "\n",
    "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "!wget -q 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
    "\n",
    "# from IPython.display import clear_output\n",
    "# clear_output()\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3de3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Necessary Libraries\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import shutil\n",
    "\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Constants and Paths\n",
    "\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "SAM_CHECKPOINT_PATH = 'sam_vit_h_4b8939.pth'\n",
    "SAM_MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "# FOOD101_PATH = '/kaggle/input/food41/food41/'\n",
    "FOOD101_PATH = 'datasets\\food_101'\n",
    "\n",
    "images_dir = os.path.join(FOOD101_PATH, 'images')\n",
    "meta_dir = os.path.join(FOOD101_PATH, 'meta/meta')\n",
    "\n",
    "# YOLOV8_DETECTION_MODEL_PATH = '/kaggle/input/your-yolov8-food-detection-dataset/best.pt'\n",
    "YOLOV8_DETECTION_MODEL_PATH = 'yolov8s.pt'\n",
    "\n",
    "OUTPUT_LABELS_DIR = 'yolo_sam_autogenerated_seg_labels'\n",
    "os.makedirs(os.path.join(OUTPUT_LABELS_DIR, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_LABELS_DIR, 'labels'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load Food-101 Categories and Create Mappings\n",
    "\n",
    "classes_file = os.path.join(meta_dir, 'classes.txt')\n",
    "\n",
    "if os.path.exists(classes_file):\n",
    "    with open(classes_file, 'r') as f:\n",
    "        categories = [line.strip() for line in f.readlines()]\n",
    "else:\n",
    "    categories = sorted(os.listdir(images_dir))\n",
    "    categories = [d for d in categories if os.path.isdir(os.path.join(images_dir, d))]\n",
    "\n",
    "num_classes_food101 = len(categories)\n",
    "category_to_id = {name: i for i, name in enumerate(categories)}\n",
    "id_to_category = {i: name for i, name in enumerate(categories)}\n",
    "\n",
    "print(f\"Loaded {num_classes_food101} food categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load YOLOv8 Object Detection Model\n",
    "\n",
    "model_yolo_detector = YOLO(YOLOV8_DETECTION_MODEL_PATH)\n",
    "model_yolo_detector.to(DEVICE)\n",
    "\n",
    "print(f\"YOLOv8 Detection model loaded from {YOLOV8_DETECTION_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize SAM Predictor\n",
    "\n",
    "sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)\n",
    "\n",
    "print(\"SAM Predictor initialized.\")\n",
    "\n",
    "def mask_to_yolov8_polygon(mask, image_width, image_height):\n",
    "    \"\"\"Converts a boolean mask to normalized polygon coordinates.\"\"\"\n",
    "\n",
    "    binary_mask_uint8 = np.ascontiguousarray(mask.astype(np.uint8) * 255)\n",
    "    contours, _ = cv2.findContours(binary_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return []\n",
    "\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    polygon_points = largest_contour.flatten().tolist()\n",
    "    \n",
    "    normalized_polygon = []\n",
    "    for i in range(0, len(polygon_points), 2):\n",
    "        x_coord, y_coord = polygon_points[i], polygon_points[i+1]\n",
    "        normalized_polygon.append(f\"{x_coord / image_width:.6f}\")\n",
    "        normalized_polygon.append(f\"{y_coord / image_height:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ee819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Automated Detection and Segmentation Loop\n",
    "\n",
    "all_image_paths = []\n",
    "for category_name in categories:\n",
    "    category_path = os.path.join(images_dir, category_name)\n",
    "    all_image_paths.extend(glob(os.path.join(category_path, '*.jpg')))\n",
    "\n",
    "\n",
    "print(f\"Starting automated detection and segmentation for {len(all_image_paths)} images...\")\n",
    "\n",
    "YOLO_CONF_THRESHOLD = 0.5\n",
    "\n",
    "for image_path in tqdm(all_image_paths, desc=\"Processing images\"):\n",
    "    try:\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        if image_bgr is None:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image_bgr.shape\n",
    "\n",
    "        results_yolo = model_yolo_detector(image_rgb, conf=YOLO_CONF_THRESHOLD, verbose=False)\n",
    "\n",
    "        yolov8_labels_lines = []\n",
    "\n",
    "        if results_yolo and len(results_yolo[0].boxes) > 0:\n",
    "            for box_data in results_yolo[0].boxes:\n",
    "                bbox_xyxy = box_data.xyxy.cpu().numpy().astype(int).flatten()\n",
    "                \n",
    "                class_id = int(box_data.cls.cpu().item())\n",
    "                confidence = float(box_data.conf.cpu().item())\n",
    "\n",
    "                if not len(bbox_xyxy) == 4:\n",
    "                    continue\n",
    "                \n",
    "                input_box_for_sam = np.array(bbox_xyxy)\n",
    "\n",
    "                sam_predictor.set_image(image_rgb)\n",
    "                \n",
    "                masks, scores, logits = sam_predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=input_box_for_sam[None, :],\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                \n",
    "                if masks.shape[0] > 0:\n",
    "                    best_mask = masks[0]\n",
    "\n",
    "                    polygon_coords = mask_to_yolov8_polygon(best_mask, w, h)\n",
    "                    \n",
    "                    if polygon_coords:\n",
    "                        yolov8_labels_lines.append(f\"{class_id} {' '.join(polygon_coords)}\")\n",
    "        \n",
    "        image_filename_base = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        output_label_path = os.path.join(OUTPUT_LABELS_DIR, 'labels', f\"{image_filename_base}.txt\")\n",
    "        \n",
    "        with open(output_label_path, 'w') as f:\n",
    "            for line in yolov8_labels_lines:\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        output_image_path = os.path.join(OUTPUT_LABELS_DIR, 'images', os.path.basename(image_path))\n",
    "        shutil.copyfile(image_path, output_image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "print(\"Automated detection and segmentation with YOLO+SAM complete! Labels saved to:\", OUTPUT_LABELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Prepare for YOLOv8 Instance Segmentation Training (Dataset Split & YAML)\n",
    "\n",
    "yolov8_data_root = 'food101_yolov8_seg_dataset_from_yolo_sam'\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'train', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'train', 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'val', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'val', 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'test', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'test', 'labels'), exist_ok=True)\n",
    "\n",
    "# Load train.txt and test.txt from Food-101 meta folder\n",
    "train_image_rel_paths = []\n",
    "test_image_rel_paths = []\n",
    "\n",
    "with open(os.path.join(meta_dir, 'train.txt'), 'r') as f:\n",
    "    train_image_rel_paths = [line.strip() + '.jpg' for line in f.readlines()]\n",
    "with open(os.path.join(meta_dir, 'test.txt'), 'r') as f:\n",
    "    test_image_rel_paths = [line.strip() + '.jpg' for line in f.readlines()]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "val_split_ratio = 0.15 # 15% of training data for validation\n",
    "train_images_for_yolo, val_images_for_yolo = train_test_split(\n",
    "    train_image_rel_paths, test_size=val_split_ratio, random_state=42\n",
    ")\n",
    "\n",
    "def copy_files(image_rel_paths, target_image_dir, target_label_dir, source_images_dir, source_labels_dir, original_food101_images_base):\n",
    "    for rel_path in tqdm(image_rel_paths, desc=f\"Copying to {os.path.basename(target_image_dir)}\"):\n",
    "        img_name = os.path.basename(rel_path)\n",
    "        label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "\n",
    "        src_original_img_path = os.path.join(original_food101_images_base, rel_path)\n",
    "        src_auto_label_path = os.path.join(source_labels_dir, label_name)\n",
    "\n",
    "        dest_img_path = os.path.join(target_image_dir, img_name)\n",
    "        dest_label_path = os.path.join(target_label_dir, label_name)\n",
    "\n",
    "        if os.path.exists(src_original_img_path) and os.path.exists(src_auto_label_path):\n",
    "            shutil.copyfile(src_original_img_path, dest_img_path)\n",
    "            shutil.copyfile(src_auto_label_path, dest_label_path)\n",
    "        else:\n",
    "            pass # print(f\"Warning: Missing file for {img_name} or its label. Skipping copy.\")\n",
    "\n",
    "print(\"\\nCopying files to YOLOv8 dataset structure...\")\n",
    "\n",
    "copy_files(train_images_for_yolo, os.path.join(yolov8_data_root, 'train', 'images'), os.path.join(yolov8_data_root, 'train', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "copy_files(val_images_for_yolo, os.path.join(yolov8_data_root, 'val', 'images'), os.path.join(yolov8_data_root, 'val', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "copy_files(test_image_rel_paths, os.path.join(yolov8_data_root, 'test', 'images'), os.path.join(yolov8_data_root, 'test', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "\n",
    "print(\"Dataset structure created and files copied.\")\n",
    "\n",
    "data_yaml_content = f\"\"\"\n",
    "path: {yolov8_data_root}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: {num_classes_food101}\n",
    "names: {categories}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml'), 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(f\"YOLOv8 data.yaml created at {os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Train YOLOv8 Instance Segmentation Model (on the newly generated dataset)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_yolov8_segmentation = YOLO('yolov8s-seg.pt') # 'n', 'm', 'l', 'x' also available\n",
    "\n",
    "print(\"\\nStarting YOLOv8 instance segmentation training on YOLO+SAM generated data...\")\n",
    "results = model_yolov8_segmentation.train(\n",
    "    data=os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml'),\n",
    "    epochs=20,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='food101_yolo_sam_seg_run',\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"YOLOv8 instance segmentation training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d703ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Evaluate and Predict with the final YOLOv8-seg model\n",
    "\n",
    "print(\"\\nEvaluating and predicting with the trained YOLOv8 segmentation model...\")\n",
    "best_model_path_yolov8_seg = os.path.join(model_yolov8_segmentation.trainer.save_dir, 'weights', 'best.pt')\n",
    "print(f\"Best YOLOv8 segmentation model saved at: {best_model_path_yolov8_seg}\")\n",
    "\n",
    "trained_yolov8_seg_model = YOLO(best_model_path_yolov8_seg)\n",
    "\n",
    "metrics = trained_yolov8_seg_model.val()\n",
    "\n",
    "test_images_folder_for_seg = os.path.join(yolov8_data_root, 'test', 'images')\n",
    "if os.path.exists(test_images_folder_for_seg) and os.listdir(test_images_folder_for_seg):\n",
    "    sample_test_image_path_for_seg = os.path.join(test_images_folder_for_seg, os.listdir(test_images_folder_for_seg)[0])\n",
    "    print(f\"Running inference on: {sample_test_image_path_for_seg}\")\n",
    "    predict_results_seg = trained_yolov8_seg_model.predict(source=sample_test_image_path_for_seg, save=True, show_conf=True, show_labels=True)\n",
    "    \n",
    "    predicted_image_output_dir_seg = predict_results_seg[0].save_dir\n",
    "    predicted_image_filename_seg = os.path.basename(sample_test_image_path_for_seg)\n",
    "    if os.path.exists(os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)):\n",
    "        print(f\"Prediction result saved to: {os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)}\")\n",
    "        display(Image.open(os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)))\n",
    "    else:\n",
    "        print(\"Predicted image file not found. Check YOLOv8 segmentation output directory.\")\n",
    "else:\n",
    "    print(\"No images found in the test set for inference demonstration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
