{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup Kaggle Environment and Install Libraries\n",
    "# --------------------------------------------------\n",
    "\n",
    "# Install ultralytics (for YOLOv8 detection)\n",
    "!pip install -q ultralytics\n",
    "\n",
    "# Install Segment Anything\n",
    "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "# Download SAM model weights (ViT-H)\n",
    "!wget -q 'https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth'\n",
    "\n",
    "# Clear output for cleaner notebook\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3de3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import Necessary Libraries\n",
    "# -----------------------------\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm # For progress bars\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import shutil # For copying files\n",
    "\n",
    "# SAM imports\n",
    "from segment_anything import sam_model_registry, SamPredictor # Use SamPredictor for bounding box prompts\n",
    "\n",
    "# YOLOv8 imports\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define Constants and Paths\n",
    "# -----------------------------\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "SAM_CHECKPOINT_PATH = 'sam_vit_h_4b8939.pth'\n",
    "SAM_MODEL_TYPE = \"vit_h\"\n",
    "\n",
    "# FOOD101_PATH = '/kaggle/input/food41/food41/'\n",
    "FOOD101_PATH = 'datasets\\food_101' # Adjust if your Food-101 path is different\n",
    "\n",
    "images_dir = os.path.join(FOOD101_PATH, 'images')\n",
    "meta_dir = os.path.join(FOOD101_PATH, 'meta') # Contains classes.txt, train.txt, test.txt\n",
    "\n",
    "# Path to your trained YOLOv8 Object Detection model for Food-101\n",
    "# You need to have trained this model previously on Food-101 for object detection.\n",
    "# Example: If you trained it on Food-101 and saved the best weights:\n",
    "# If you uploaded it as a Kaggle dataset:\n",
    "\n",
    "# YOLOV8_DETECTION_MODEL_PATH = '/kaggle/input/your-yolov8-food-detection-dataset/best.pt' # ADJUST THIS TO BEST MODEL\n",
    "# If you just want to test with a general YOLOv8 model (less accurate for food types):\n",
    "YOLOV8_DETECTION_MODEL_PATH = 'yolov8s.pt' # Downloaded by ultralytics automatically\n",
    "\n",
    "OUTPUT_LABELS_DIR = 'yolo_sam_autogenerated_seg_labels'\n",
    "os.makedirs(os.path.join(OUTPUT_LABELS_DIR, 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_LABELS_DIR, 'labels'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3838bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load Food-101 Categories and Create Mappings\n",
    "# ------------------------------------------------\n",
    "classes_file = os.path.join(meta_dir, 'classes.txt')\n",
    "if os.path.exists(classes_file):\n",
    "    with open(classes_file, 'r') as f:\n",
    "        categories = [line.strip() for line in f.readlines()]\n",
    "else:\n",
    "    categories = sorted(os.listdir(images_dir))\n",
    "    categories = [d for d in categories if os.path.isdir(os.path.join(images_dir, d))]\n",
    "\n",
    "num_classes_food101 = len(categories)\n",
    "category_to_id = {name: i for i, name in enumerate(categories)}\n",
    "id_to_category = {i: name for i, name in enumerate(categories)}\n",
    "\n",
    "print(f\"Loaded {num_classes_food101} food categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395bc010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load YOLOv8 Object Detection Model\n",
    "# -------------------------------------\n",
    "model_yolo_detector = YOLO(YOLOV8_DETECTION_MODEL_PATH)\n",
    "model_yolo_detector.to(DEVICE)\n",
    "print(f\"YOLOv8 Detection model loaded from {YOLOV8_DETECTION_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4594eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Initialize SAM Predictor\n",
    "# ---------------------------\n",
    "sam = sam_model_registry[SAM_MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam) # Use SamPredictor for specific prompts (bounding boxes)\n",
    "print(\"SAM Predictor initialized.\")\n",
    "\n",
    "# Helper function to convert mask to polygon points for YOLOv8 segmentation format\n",
    "def mask_to_yolov8_polygon(mask, image_width, image_height):\n",
    "    \"\"\"Converts a boolean mask to normalized polygon coordinates.\"\"\"\n",
    "    # Find contours from the mask\n",
    "    # `np.ascontiguousarray` is important for cv2.findContours\n",
    "    binary_mask_uint8 = np.ascontiguousarray(mask.astype(np.uint8) * 255)\n",
    "    contours, _ = cv2.findContours(binary_mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return []\n",
    "\n",
    "    # Take the largest contour (assuming it's the primary object)\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Flatten and normalize polygon points\n",
    "    polygon_points = largest_contour.flatten().tolist()\n",
    "    \n",
    "    normalized_polygon = []\n",
    "    for i in range(0, len(polygon_points), 2):\n",
    "        x_coord, y_coord = polygon_points[i], polygon_points[i+1]\n",
    "        normalized_polygon.append(f\"{x_coord / image_width:.6f}\")\n",
    "        normalized_polygon.append(f\"{y_coord / image_height:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ee819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Automated Detection and Segmentation Loop\n",
    "# --------------------------------------------\n",
    "\n",
    "# Get all image paths from Food-101 (or a subset for testing)\n",
    "all_image_paths = []\n",
    "for category_name in categories:\n",
    "    category_path = os.path.join(images_dir, category_name)\n",
    "    all_image_paths.extend(glob(os.path.join(category_path, '*.jpg')))\n",
    "\n",
    "# Optional: Process a smaller subset for initial testing\n",
    "# all_image_paths = all_image_paths[:100]\n",
    "\n",
    "print(f\"Starting automated detection and segmentation for {len(all_image_paths)} images...\")\n",
    "\n",
    "# Define a confidence threshold for YOLOv8 detections\n",
    "YOLO_CONF_THRESHOLD = 0.5 # Adjust as needed\n",
    "\n",
    "for image_path in tqdm(all_image_paths, desc=\"Processing images\"):\n",
    "    try:\n",
    "        image_bgr = cv2.imread(image_path)\n",
    "        if image_bgr is None:\n",
    "            print(f\"Warning: Could not read image {image_path}. Skipping.\")\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "        h, w, _ = image_bgr.shape\n",
    "\n",
    "        # Stage 1: YOLOv8 Object Detection\n",
    "        # Pass the image to YOLOv8 detector\n",
    "        results_yolo = model_yolo_detector(image_rgb, conf=YOLO_CONF_THRESHOLD, verbose=False) # verbose=False for cleaner output\n",
    "\n",
    "        yolov8_labels_lines = []\n",
    "\n",
    "        # Process detections from YOLOv8\n",
    "        if results_yolo and len(results_yolo[0].boxes) > 0:\n",
    "            for box_data in results_yolo[0].boxes:\n",
    "                # Extract bounding box (xyxy format: x_min, y_min, x_max, y_max)\n",
    "                # Ensure it's on CPU and converted to numpy for SAMPredictor\n",
    "                bbox_xyxy = box_data.xyxy.cpu().numpy().astype(int).flatten()\n",
    "                \n",
    "                # Extract class ID and confidence\n",
    "                class_id = int(box_data.cls.cpu().item())\n",
    "                confidence = float(box_data.conf.cpu().item())\n",
    "\n",
    "                # Make sure the bounding box is valid\n",
    "                if not len(bbox_xyxy) == 4:\n",
    "                    continue\n",
    "                \n",
    "                # SAM expects bounding boxes in (x_min, y_min, x_max, y_max) format\n",
    "                input_box_for_sam = np.array(bbox_xyxy)\n",
    "\n",
    "                # Stage 2: SAM Segmentation using YOLO's Bounding Box as Prompt\n",
    "                sam_predictor.set_image(image_rgb)\n",
    "                \n",
    "                # Use multimask_output=False if you expect one main object per box\n",
    "                # If a box might contain multiple subtle objects, you could try True and pick best score\n",
    "                masks, scores, logits = sam_predictor.predict(\n",
    "                    point_coords=None,\n",
    "                    point_labels=None,\n",
    "                    box=input_box_for_sam[None, :], # SAM expects (N, 4) for boxes\n",
    "                    multimask_output=False\n",
    "                )\n",
    "                \n",
    "                # Take the first (and usually only) mask if multimask_output=False\n",
    "                if masks.shape[0] > 0:\n",
    "                    best_mask = masks[0] # This is a boolean mask (H, W)\n",
    "\n",
    "                    # Convert SAM mask to YOLOv8 polygon format\n",
    "                    polygon_coords = mask_to_yolov8_polygon(best_mask, w, h)\n",
    "                    \n",
    "                    if polygon_coords: # Ensure a valid polygon was extracted\n",
    "                        # YOLOv8 format: <class_id> <normalized_polygon_coords>\n",
    "                        yolov8_labels_lines.append(f\"{class_id} {' '.join(polygon_coords)}\")\n",
    "        \n",
    "        # Save the YOLOv8 format labels to a .txt file\n",
    "        image_filename_base = os.path.splitext(os.path.basename(image_path))[0]\n",
    "        output_label_path = os.path.join(OUTPUT_LABELS_DIR, 'labels', f\"{image_filename_base}.txt\")\n",
    "        \n",
    "        with open(output_label_path, 'w') as f:\n",
    "            for line in yolov8_labels_lines:\n",
    "                f.write(line + '\\n')\n",
    "\n",
    "        # Copy the original image to the output folder to create a complete dataset\n",
    "        output_image_path = os.path.join(OUTPUT_LABELS_DIR, 'images', os.path.basename(image_path))\n",
    "        shutil.copyfile(image_path, output_image_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "print(\"Automated detection and segmentation with YOLO+SAM complete! Labels saved to:\", OUTPUT_LABELS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b1a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Prepare for YOLOv8 Instance Segmentation Training (Dataset Split & YAML)\n",
    "# -------------------------------------------------------------------------\n",
    "# This section is identical to the previous answer, as the output format is the same.\n",
    "# You'll use the 'yolo_sam_autogenerated_seg_labels' directory as your source for images and labels.\n",
    "\n",
    "yolov8_data_root = 'food101_yolov8_seg_dataset_from_yolo_sam'\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'train', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'train', 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'val', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'val', 'labels'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'test', 'images'), exist_ok=True)\n",
    "os.makedirs(os.path.join(yolov8_data_root, 'test', 'labels'), exist_ok=True)\n",
    "\n",
    "# Load train.txt and test.txt from Food-101 meta folder\n",
    "train_image_rel_paths = []\n",
    "test_image_rel_paths = []\n",
    "\n",
    "with open(os.path.join(meta_dir, 'train.txt'), 'r') as f:\n",
    "    train_image_rel_paths = [line.strip() + '.jpg' for line in f.readlines()]\n",
    "with open(os.path.join(meta_dir, 'test.txt'), 'r') as f:\n",
    "    test_image_rel_paths = [line.strip() + '.jpg' for line in f.readlines()]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "val_split_ratio = 0.15 # 15% of training data for validation\n",
    "train_images_for_yolo, val_images_for_yolo = train_test_split(\n",
    "    train_image_rel_paths, test_size=val_split_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Function to copy images and their corresponding labels\n",
    "def copy_files(image_rel_paths, target_image_dir, target_label_dir, source_images_dir, source_labels_dir, original_food101_images_base):\n",
    "    for rel_path in tqdm(image_rel_paths, desc=f\"Copying to {os.path.basename(target_image_dir)}\"):\n",
    "        img_name = os.path.basename(rel_path)\n",
    "        label_name = os.path.splitext(img_name)[0] + '.txt'\n",
    "\n",
    "        # Construct path to original Food-101 image (for copying the image)\n",
    "        src_original_img_path = os.path.join(original_food101_images_base, rel_path)\n",
    "        # Construct path to the auto-generated label (from our YOLO+SAM process)\n",
    "        src_auto_label_path = os.path.join(source_labels_dir, label_name)\n",
    "\n",
    "        dest_img_path = os.path.join(target_image_dir, img_name)\n",
    "        dest_label_path = os.path.join(target_label_dir, label_name)\n",
    "\n",
    "        if os.path.exists(src_original_img_path) and os.path.exists(src_auto_label_path):\n",
    "            shutil.copyfile(src_original_img_path, dest_img_path)\n",
    "            shutil.copyfile(src_auto_label_path, dest_label_path)\n",
    "        else:\n",
    "            # This can happen if an image had no food items detected or below confidence\n",
    "            # You might choose to skip these or generate empty label files.\n",
    "            pass # print(f\"Warning: Missing file for {img_name} or its label. Skipping copy.\")\n",
    "\n",
    "print(\"\\nCopying files to YOLOv8 dataset structure...\")\n",
    "\n",
    "copy_files(train_images_for_yolo, os.path.join(yolov8_data_root, 'train', 'images'), os.path.join(yolov8_data_root, 'train', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "copy_files(val_images_for_yolo, os.path.join(yolov8_data_root, 'val', 'images'), os.path.join(yolov8_data_root, 'val', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "copy_files(test_image_rel_paths, os.path.join(yolov8_data_root, 'test', 'images'), os.path.join(yolov8_data_root, 'test', 'labels'), images_dir, os.path.join(OUTPUT_LABELS_DIR, 'labels'), images_dir)\n",
    "\n",
    "print(\"Dataset structure created and files copied.\")\n",
    "\n",
    "# Create data.yaml for YOLOv8 Instance Segmentation training\n",
    "data_yaml_content = f\"\"\"\n",
    "path: {yolov8_data_root}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "nc: {num_classes_food101}\n",
    "names: {categories}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml'), 'w') as f:\n",
    "    f.write(data_yaml_content)\n",
    "\n",
    "print(f\"YOLOv8 data.yaml created at {os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Train YOLOv8 Instance Segmentation Model (on the newly generated dataset)\n",
    "# ---------------------------------------------------------------------------\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLOv8 segmentation model\n",
    "model_yolov8_segmentation = YOLO('yolov8s-seg.pt') # 'n', 'm', 'l', 'x' also available\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nStarting YOLOv8 instance segmentation training on YOLO+SAM generated data...\")\n",
    "results = model_yolov8_segmentation.train(\n",
    "    data=os.path.join(yolov8_data_root, 'food101_yolov8_seg_yolo_sam.yaml'),\n",
    "    epochs=50, # Adjust\n",
    "    imgsz=640,\n",
    "    batch=16,  # Adjust based on GPU memory.\n",
    "    name='food101_yolo_sam_seg_run',\n",
    "    device=0\n",
    ")\n",
    "\n",
    "print(\"YOLOv8 instance segmentation training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d703ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. (Optional) Evaluate and Predict with the final YOLOv8-seg model\n",
    "# --------------------------------------------------------------------\n",
    "print(\"\\nEvaluating and predicting with the trained YOLOv8 segmentation model...\")\n",
    "best_model_path_yolov8_seg = os.path.join(model_yolov8_segmentation.trainer.save_dir, 'weights', 'best.pt')\n",
    "print(f\"Best YOLOv8 segmentation model saved at: {best_model_path_yolov8_seg}\")\n",
    "\n",
    "trained_yolov8_seg_model = YOLO(best_model_path_yolov8_seg)\n",
    "\n",
    "# Evaluate on the test set\n",
    "metrics = trained_yolov8_seg_model.val()\n",
    "\n",
    "# Run inference on a sample image from the test set\n",
    "test_images_folder_for_seg = os.path.join(yolov8_data_root, 'test', 'images')\n",
    "if os.path.exists(test_images_folder_for_seg) and os.listdir(test_images_folder_for_seg):\n",
    "    sample_test_image_path_for_seg = os.path.join(test_images_folder_for_seg, os.listdir(test_images_folder_for_seg)[0])\n",
    "    print(f\"Running inference on: {sample_test_image_path_for_seg}\")\n",
    "    predict_results_seg = trained_yolov8_seg_model.predict(source=sample_test_image_path_for_seg, save=True, show_conf=True, show_labels=True)\n",
    "    \n",
    "    # Display the predicted image\n",
    "    from PIL import Image\n",
    "    from IPython.display import display\n",
    "\n",
    "    predicted_image_output_dir_seg = predict_results_seg[0].save_dir\n",
    "    predicted_image_filename_seg = os.path.basename(sample_test_image_path_for_seg)\n",
    "    if os.path.exists(os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)):\n",
    "        print(f\"Prediction result saved to: {os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)}\")\n",
    "        display(Image.open(os.path.join(predicted_image_output_dir_seg, predicted_image_filename_seg)))\n",
    "    else:\n",
    "        print(\"Predicted image file not found. Check YOLOv8 segmentation output directory.\")\n",
    "else:\n",
    "    print(\"No images found in the test set for inference demonstration.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
